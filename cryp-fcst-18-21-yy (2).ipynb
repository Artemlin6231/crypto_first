{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":30894,"databundleVersionId":3147400,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom multiprocessing import Pool\nimport gc\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.multioutput import MultiOutputRegressor\n\nfrom scipy.stats import pearsonr\nimport lightgbm as lgb\n#import shap","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:15:27.927532Z","iopub.execute_input":"2025-12-17T02:15:27.927892Z","iopub.status.idle":"2025-12-17T02:15:31.848679Z","shell.execute_reply.started":"2025-12-17T02:15:27.927864Z","shell.execute_reply":"2025-12-17T02:15:31.847641Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# **1. Data loading**","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:15:36.644947Z","iopub.execute_input":"2025-12-17T02:15:36.646932Z","iopub.status.idle":"2025-12-17T02:15:36.658328Z","shell.execute_reply.started":"2025-12-17T02:15:36.646878Z","shell.execute_reply":"2025-12-17T02:15:36.656681Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/g-research-crypto-forecasting/example_sample_submission.csv\n/kaggle/input/g-research-crypto-forecasting/asset_details.csv\n/kaggle/input/g-research-crypto-forecasting/example_test.csv\n/kaggle/input/g-research-crypto-forecasting/train.csv\n/kaggle/input/g-research-crypto-forecasting/supplemental_train.csv\n/kaggle/input/g-research-crypto-forecasting/gresearch_crypto/competition.cpython-37m-x86_64-linux-gnu.so\n/kaggle/input/g-research-crypto-forecasting/gresearch_crypto/__init__.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/g-research-crypto-forecasting/train.csv')\nsupplemental = pd.read_csv('/kaggle/input/g-research-crypto-forecasting/supplemental_train.csv')\n\nsupplemental['timestamp_dt'] = pd.to_datetime(supplemental['timestamp'], unit='s')\ndata['timestamp_dt'] = pd.to_datetime(data['timestamp'], unit='s')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:15:39.447190Z","iopub.execute_input":"2025-12-17T02:15:39.448341Z","iopub.status.idle":"2025-12-17T02:16:32.925945Z","shell.execute_reply.started":"2025-12-17T02:15:39.448301Z","shell.execute_reply":"2025-12-17T02:16:32.924687Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"weights_assets = pd.read_csv('/kaggle/input/g-research-crypto-forecasting/asset_details.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:16:37.007149Z","iopub.execute_input":"2025-12-17T02:16:37.007585Z","iopub.status.idle":"2025-12-17T02:16:37.019845Z","shell.execute_reply.started":"2025-12-17T02:16:37.007553Z","shell.execute_reply":"2025-12-17T02:16:37.018299Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"assets = data['Asset_ID'].unique().tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:16:41.094735Z","iopub.execute_input":"2025-12-17T02:16:41.095226Z","iopub.status.idle":"2025-12-17T02:16:41.273576Z","shell.execute_reply.started":"2025-12-17T02:16:41.095170Z","shell.execute_reply":"2025-12-17T02:16:41.272470Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"n_plots = 2\nfor i in range(0, len(assets), n_plots):\n    batch = assets[i:i+n_plots]\n    fig, axes = plt.subplots(1, len(batch), figsize=(5*len(batch), 4))\n    \n    for ax, asset_id in zip(axes, batch):\n        data_main = data[data['Asset_ID'] == asset_id].sort_values('timestamp')\n        ax.plot(data_main['timestamp'], data_main['VWAP'], color='blue', label='Data')\n        \n        if 'Asset_ID' in supplemental.columns:\n            data_supp = supplemental[supplemental['Asset_ID'] == asset_id].sort_values('timestamp')\n            if not data_supp.empty:\n                ax.plot(data_supp['timestamp'], data_supp['VWAP'], color='red', label='Supplemental data')\n        \n        ax.set_title(f'Asset {asset_id}: VWAP over time')\n        ax.set_xlabel('Timestamp')\n        ax.set_ylabel('VWAP')\n        ax.grid(True)\n        ax.legend()\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test = (supplemental.sort_values([\"Asset_ID\", \"timestamp\"]).reset_index(drop=True))\ntrain = (data.sort_values([\"Asset_ID\", \"timestamp\"]).reset_index(drop=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:16:44.646700Z","iopub.execute_input":"2025-12-17T02:16:44.647173Z","iopub.status.idle":"2025-12-17T02:16:51.760512Z","shell.execute_reply.started":"2025-12-17T02:16:44.647132Z","shell.execute_reply":"2025-12-17T02:16:51.759409Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"del supplemental, data\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:16:53.624423Z","iopub.execute_input":"2025-12-17T02:16:53.624752Z","iopub.status.idle":"2025-12-17T02:16:53.797068Z","shell.execute_reply.started":"2025-12-17T02:16:53.624730Z","shell.execute_reply":"2025-12-17T02:16:53.796155Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"30"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# **2. Data preprocessing**","metadata":{}},{"cell_type":"code","source":"def make_regular_series(df_asset, asset, method='pad', col='timestamp'):\n    \"\"\"\n    Function makes the time series regular by timestamp.\n    df_asset — filtered DataFrame by Asset_ID \n    \"\"\"\n    df_asset = df_asset.set_index(col)\n    \n    min_time = df_asset.index.min()\n    max_time = df_asset.index.max()\n    \n    df_asset = df_asset.reindex(\n        range(min_time, max_time + 60, 60),\n        method=method\n    )\n    \n    return df_asset\n\nassets = train['Asset_ID'].unique().tolist()\ngroups = {asset: train[train['Asset_ID'] == asset].copy() for asset in assets}\n\nwith Pool(3) as pool:\n    results = pool.starmap(make_regular_series, [(groups[asset], asset) for asset in assets])\n\ntrain_all_regular = pd.concat(results)\ntrain_all_regular = train_all_regular.reset_index().set_index(['timestamp','Asset_ID'], drop=False)\n\ndel results\ndel groups\ngc.collect()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:17:01.741123Z","iopub.execute_input":"2025-12-17T02:17:01.741696Z","iopub.status.idle":"2025-12-17T02:17:30.820991Z","shell.execute_reply.started":"2025-12-17T02:17:01.741656Z","shell.execute_reply":"2025-12-17T02:17:30.818009Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# All fillings instead of 0 will provide leakage \ntrain_all_regular['Target'] = train_all_regular['Target'].fillna(0)\n\ntrain_all_regular['VWAP'] = (\n    train_all_regular['VWAP']\n    .replace([np.inf, -np.inf], np.nan)  \n    .ffill()                              \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:17:36.498055Z","iopub.execute_input":"2025-12-17T02:17:36.499897Z","iopub.status.idle":"2025-12-17T02:17:37.567649Z","shell.execute_reply.started":"2025-12-17T02:17:36.499841Z","shell.execute_reply":"2025-12-17T02:17:37.566344Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"ratio_zeros = (train_all_regular['Target'] == 0).sum() / (train_all_regular['Target'] != 0).sum()\nprint(ratio_zeros)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scalers_log = {}\nscalers_rob = {}\nscalers_y_rl = {}\n\ntrain_scaled_list = []\ntest_scaled_list = []\nfeatures_to_log_scale = ['Volume', 'Count']\nfeatures_to_rob_scale = [\"Open\", \"High\", \"Low\", \"Close\", \"VWAP\"]\ny_col = [\"Target\"]\n\nfeatures = [\"Count\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"VWAP\"]\nx_cols = [\"Asset_ID\"] + features\nall_cols = x_cols + y_col\n\nfor asset in train_all_regular[\"Asset_ID\"].unique():\n    df_a = train_all_regular.loc[train_all_regular.Asset_ID == asset, :].copy()\n    \n    df_a[features_to_log_scale] = np.log1p(df_a[features_to_log_scale])\n    scalers_log[asset] = \"log1p\"\n    \n    scaler = RobustScaler()\n    df_a[features_to_rob_scale] = scaler.fit_transform(df_a[features_to_rob_scale])\n    scalers_rob[asset] = scaler\n    \n    scaler_y = StandardScaler()\n    df_a[y_col] = scaler_y.fit_transform(df_a[y_col])\n    scalers_y_rl[asset] = scaler_y\n\n    train_scaled_list.append(df_a[all_cols])\n\ntrain_log_rob = pd.concat(train_scaled_list)\n\n# Same test normalization\nfor asset in test[\"Asset_ID\"].unique():\n    df_test_rl = test[test.Asset_ID == asset].copy()\n    df_test_rl[features_to_log_scale] = np.log1p(df_test_rl[features_to_log_scale])\n    df_test_rl[features_to_rob_scale] = scalers_rob[asset].transform(df_test_rl[features_to_rob_scale])\n    test_scaled_list.append(df_test_rl[all_cols + ['timestamp']])\n \ntest_log_rob = pd.concat(test_scaled_list)\ntest_log_rob = test_log_rob.set_index(['timestamp', 'Asset_ID'], drop=False)\n\ndel train_scaled_list\ndel test_scaled_list\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:18:07.984411Z","iopub.execute_input":"2025-12-17T02:18:07.984749Z","iopub.status.idle":"2025-12-17T02:18:24.441923Z","shell.execute_reply.started":"2025-12-17T02:18:07.984724Z","shell.execute_reply":"2025-12-17T02:18:24.440989Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"del train, test, train_all_regular\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:19:09.027159Z","iopub.execute_input":"2025-12-17T02:19:09.027564Z","iopub.status.idle":"2025-12-17T02:19:09.212990Z","shell.execute_reply.started":"2025-12-17T02:19:09.027538Z","shell.execute_reply":"2025-12-17T02:19:09.211794Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"# **3. Baseline**\n## **3.1 Linear regression**","metadata":{}},{"cell_type":"code","source":"def weighted_pearsonr(x, y, w):\n    \"\"\"\n    Count weighted pearson correlation coefficient.\n    x - tested data\n    y - predicted data\n    w - weights\n    \"\"\"\n    x = np.asarray(x)\n    y = np.asarray(y)\n    w = np.asarray(w)\n\n    mask = np.isfinite(x) & np.isfinite(y) & np.isfinite(w)\n    x, y, w = x[mask], y[mask], w[mask]\n\n    if len(x) == 0:\n        return np.nan\n\n    w_sum = np.sum(w)\n    if w_sum == 0:\n        return np.nan\n\n    mx = np.sum(w * x) / w_sum\n    my = np.sum(w * y) / w_sum\n\n    cov = np.sum(w * (x - mx) * (y - my))\n    vx  = np.sum(w * (x - mx) ** 2)\n    vy  = np.sum(w * (y - my) ** 2)\n\n    if vx <= 0 or vy <= 0:\n        return np.nan\n\n    return cov / np.sqrt(vx * vy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:19:12.292423Z","iopub.execute_input":"2025-12-17T02:19:12.292737Z","iopub.status.idle":"2025-12-17T02:19:12.301095Z","shell.execute_reply.started":"2025-12-17T02:19:12.292717Z","shell.execute_reply":"2025-12-17T02:19:12.300089Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"asset_weights = weights_assets.set_index('Asset_ID')['Weight'].to_dict()\ncoins = train_log_rob['Asset_ID'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:19:19.528732Z","iopub.execute_input":"2025-12-17T02:19:19.529078Z","iopub.status.idle":"2025-12-17T02:19:19.700497Z","shell.execute_reply.started":"2025-12-17T02:19:19.529051Z","shell.execute_reply":"2025-12-17T02:19:19.699460Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"all_mses = []\nall_corrs = []\n\nall_y_true = []\nall_y_pred = []\nall_weights = []\n\nfor coin in coins:\n\n    X_train_coin = train_log_rob[train_log_rob['Asset_ID'] == coin][x_cols]\n    y_train_coin = train_log_rob[train_log_rob['Asset_ID'] == coin][y_col]\n    \n    X_test_coin = test_log_rob[test_log_rob['Asset_ID'] == coin][x_cols]\n    y_test_coin = test_log_rob[test_log_rob['Asset_ID'] == coin][y_col].fillna(0)\n    \n    lr = LinearRegression()\n    lr.fit(X_train_coin, y_train_coin)\n    y_pred_coin = lr.predict(X_test_coin)\n\n    y_test_1d = np.ravel(y_test_coin)\n    y_pred_1d = np.ravel(y_pred_coin)\n\n    corr_coin, _ = pearsonr(y_test_1d, y_pred_1d)\n    mse_coin = mean_squared_error(y_test_1d, y_pred_1d)\n\n    all_mses.append(mse_coin)\n    all_corrs.append(corr_coin)\n\n    w = asset_weights[coin]\n    all_y_true.append(y_test_1d)\n    all_y_pred.append(y_pred_1d)\n    all_weights.append(np.full_like(y_test_1d, w, dtype=float))\n\n    del X_train_coin, y_train_coin\n    gc.collect()\n    \n    plt.figure(figsize=(6,6))\n    plt.scatter(y_test_coin, y_pred_coin, alpha=0.3)\n    plt.plot([y_test_coin.min(), y_test_coin.max()],\n             [y_test_coin.min(), y_test_coin.max()],\n             color='red', linestyle='--')\n    plt.xlabel(\"True Target\")\n    plt.ylabel(\"Predicted Target\")\n    plt.title(f\"LR Baseline: Robust+log Scaled — {coin}\\nMSE: {mse_coin:.4f}, Pearson: {corr_coin:.4f}\")\n    plt.show()\n\noverall_mse = np.mean(all_mses)\noverall_corr = np.mean(all_corrs)\n\nprint(f\"Aggregated MSE: {overall_mse:.6f}\")\nprint(f\"Aggregated Pearson Correlation: {overall_corr:.6f}\")\n\ny_true_all = np.concatenate(all_y_true)\ny_pred_all = np.concatenate(all_y_pred)\nw_all      = np.concatenate(all_weights)\n\nweighted_corr = weighted_pearsonr(y_true_all, y_pred_all, w_all)\n\nprint(f\"Aggregated Weighted Pearson: {weighted_corr:.6f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2 Constant model","metadata":{}},{"cell_type":"code","source":"all_mses = []\nall_corrs = []\n\nfor coin in coins:\n\n    y_test_coin = test_log_rob[test_log_rob['Asset_ID'] == coin][y_col].fillna(0)\n\n    y_pred_coin = np.zeros_like(y_test_coin)\n\n    y_test_1d = np.ravel(y_test_coin)\n    y_pred_1d = np.ravel(y_pred_coin)\n    \n    mse_coin = mean_squared_error(y_test_1d, y_pred_1d)\n    \n    all_mses.append(mse_coin)\n    \n    print(f\"{coin}: MSE={mse_coin:.8f}\")\n    del y_test_coin, y_pred_coin, y_test_1d, y_pred_1d\n    gc.collect()\n\noverall_mse = np.mean(all_mses)\nprint(f\"\\nAggregated MSE: {overall_mse:.8f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.3 Multioutput regression","metadata":{}},{"cell_type":"code","source":"X_train = train_log_rob[x_cols]\nX_test  = test_log_rob[x_cols]\ny_train = train_log_rob[y_col]\ny_test  = test_log_rob[y_col]\n\nmlr = MultiOutputRegressor(LinearRegression())\nmlr.fit(X_train, y_train)\ny_pred = mlr.predict(X_test)\n\ny_true = np.nan_to_num(y_test.values.ravel(), nan=0.0)\ny_pred_vals = np.nan_to_num(y_pred.ravel(), nan=0.0)\n\nmse = mean_squared_error(y_true, y_pred_vals)\ncorr, _ = pearsonr(y_true, y_pred_vals)\n\nprint(f\"MSE={mse:.6f}, Pearson={corr:.4f}\")\n \nweights = test_log_rob['Asset_ID'].map(asset_weights).values\nweights = np.nan_to_num(weights, nan=0.0)\n\nweighted_corr = weighted_pearsonr(y_true, y_pred_vals, weights)\nprint(f\"Weighted Pearson={weighted_corr:.6f}\")\n\ndel X_train, X_test, y_train, y_test\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **4. Feature engineering**","metadata":{}},{"cell_type":"code","source":"CORR_GROUP = [0, 8, 10, 11, 13]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:23:23.923374Z","iopub.execute_input":"2025-12-17T02:23:23.923762Z","iopub.status.idle":"2025-12-17T02:23:23.928897Z","shell.execute_reply.started":"2025-12-17T02:23:23.923740Z","shell.execute_reply":"2025-12-17T02:23:23.927812Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def add_features_per_asset(df):\n    df = df.copy()\n    new_cols = {}\n\n    for lag in [1, 5, 15, 55]:\n        new_cols[f'Close_lag{lag}'] = df['Close'].shift(lag)\n\n    # log-return \n    safe_close = df['Close'].replace(0, np.nan)\n    log_ret = np.log(safe_close / safe_close.shift(1))\n    log_ret = log_ret.replace([np.inf, -np.inf], np.nan).fillna(0)\n    new_cols['Close_log_ret'] = log_ret\n\n    # volatility\n    new_cols['Close_vol_10'] = log_ret.rolling(10).std().fillna(0)\n    new_cols['Close_vol_50'] = log_ret.rolling(50).std().fillna(0)\n\n    # EMA\n    new_cols['Close_ema_10'] = df['Close'].ewm(span=10, adjust=False).mean()\n    new_cols['Close_ema_50'] = df['Close'].ewm(span=50, adjust=False).mean()\n\n    # VWAP lags\n    new_cols['VWAP_lag1'] = df['VWAP'].shift(1)\n    new_cols['VWAP_lag5'] = df['VWAP'].shift(5)\n\n    # Candle features\n    new_cols['Upper_Shadow'] = df['High'] - np.maximum(df['Close'], df['Open'])\n    new_cols['Lower_Shadow'] = np.minimum(df['Close'], df['Open']) - df['Low']\n    denom = (df['Close'] - df['Open']).replace(0, np.nan)\n    new_cols['hlco_ratio'] = (df['High'] - df['Low']) / denom\n\n    df_new = pd.concat([df, pd.DataFrame(new_cols, index=df.index)], axis=1)\n    df_new = df_new.replace([np.inf, -np.inf], 0).fillna(0)\n\n    del new_cols, log_ret, safe_close, denom\n    gc.collect()\n    return df_new\n\n\ndef add_cross_asset_corr_features(df, corr_assets):\n    \"\"\"\n    df: DataFrame with MultiIndex (timestamp, Asset_ID) or with Asset_ID column.\n    corr_assets: list of asset ids that form the correlated group.\n    Returns df with two new columns:\n      - corr_group_log_ret : mean log-return of the corr_assets at the same timestamp\n      - corr_log_ret_diff  : Close_log_ret - corr_group_log_ret\n    \"\"\"\n    df = df.copy()\n\n    if 'Close_log_ret' not in df.columns:\n        safe_close = df['Close'].replace(0, np.nan)\n        df['Close_log_ret'] = np.log(safe_close / safe_close.shift(1))\n        df['Close_log_ret'] = df['Close_log_ret'].replace([np.inf, -np.inf], np.nan).fillna(0)\n        del safe_close\n\n    if 'Asset_ID' in df.columns:\n        asset_vals = df['Asset_ID']\n    else:\n        try:\n            asset_vals = df.index.get_level_values(1)\n        except Exception:\n            raise ValueError(\"DataFrame must have 'Asset_ID' column or be indexed by (timestamp, Asset_ID) MultiIndex.\")\n\n    # boolean mask for correlated group (aligned with df)\n    mask = np.isin(asset_vals, corr_assets)\n    # subset of rows that belong to corr group\n    df_corr = df[mask].copy()\n\n    if df_corr.shape[0] == 0:\n        df['corr_group_log_ret'] = 0.0\n        df['corr_log_ret_diff']  = df['Close_log_ret'] - df['corr_group_log_ret']\n        df = df.fillna(0)\n        return df\n\n    if isinstance(df_corr.index, pd.MultiIndex):\n        ts_corr_index = df_corr.index.get_level_values(0)\n    else:\n        ts_corr_index = df_corr.index\n\n    group_ret = df_corr.groupby(ts_corr_index)['Close_log_ret'].mean()\n  \n    if isinstance(df.index, pd.MultiIndex):\n        ts_all = df.index.get_level_values(0)\n    else:\n        ts_all = df.index\n\n    corr_group_values = group_ret.reindex(ts_all).values\n\n    df['corr_group_log_ret'] = pd.Series(corr_group_values, index=df.index).fillna(0)\n    df['corr_log_ret_diff']  = df['Close_log_ret'] - df['corr_group_log_ret']\n\n    del df_corr, group_ret, ts_corr_index, ts_all, mask, asset_vals, corr_group_values\n    gc.collect()\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:23:27.830019Z","iopub.execute_input":"2025-12-17T02:23:27.830476Z","iopub.status.idle":"2025-12-17T02:24:10.553444Z","shell.execute_reply.started":"2025-12-17T02:23:27.830448Z","shell.execute_reply":"2025-12-17T02:24:10.552286Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"assets = train_log_rob.index.get_level_values(1).unique()\nparts = []\nfor asset in assets:\n    df_asset = train_log_rob.xs(asset, level=1).copy()  \n    df_asset['Asset_ID'] = asset                         \n    df_feat = add_features_per_asset(df_asset)\n    parts.append(df_feat)\n    del df_asset, df_feat\n    gc.collect()\ntrain_features = pd.concat(parts)\ndel parts; gc.collect()\ntrain_features = add_cross_asset_corr_features(train_features, CORR_GROUP)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"parts_ = []\n\nfor asset in assets:\n    df_asset = test_log_rob[test_log_rob['Asset_ID'] == asset].copy()                        \n    df_feat = add_features_per_asset(df_asset)\n    parts_.append(df_feat)\n    del df_asset, df_feat\n    gc.collect()\ntest_features = pd.concat(parts_)\ndel parts_; gc.collect()\ntest_features = add_cross_asset_corr_features(test_features, CORR_GROUP)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:24:14.496744Z","iopub.execute_input":"2025-12-17T02:24:14.497095Z","iopub.status.idle":"2025-12-17T02:24:21.862646Z","shell.execute_reply.started":"2025-12-17T02:24:14.497064Z","shell.execute_reply":"2025-12-17T02:24:21.861645Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"'''\nThe warning is most likely due to the fact that at the beginning there are no previous values \n(lags) and NaN are returned, but this is not a problem for the model.\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **5. Model development**","metadata":{}},{"cell_type":"code","source":"x_cols = [c for c in train_features.columns if c not in ['Asset_ID', y_col]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:25:05.734296Z","iopub.execute_input":"2025-12-17T02:25:05.734692Z","iopub.status.idle":"2025-12-17T02:25:05.740569Z","shell.execute_reply.started":"2025-12-17T02:25:05.734668Z","shell.execute_reply":"2025-12-17T02:25:05.739525Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"params = {\n    'objective': 'regression',\n    'metric': 'mse',\n    'boosting_type': 'gbdt',\n    'num_leaves': 31,\n    'max_depth': -1,\n    'min_data_in_leaf': 50, ##\n    'learning_rate': 0.01,\n    'feature_fraction': 0.8,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 1,\n    'lambda_l2': 10, ## \n    'verbosity': -1,\n    'random_state': 42\n}\n\nall_y_true = []\nall_y_pred = []\nall_weights = []\n\nfor asset in tqdm(assets, desc=\"Assets\"):\n    df_train_asset = train_features[train_features['Asset_ID'] == asset].copy()\n    df_test_asset  = test_features[test_features['Asset_ID'] == asset].copy()\n    \n    X_train_full = df_train_asset[x_cols].fillna(0)\n    y_train_full = df_train_asset[y_col].fillna(0).values.ravel()\n    X_test_asset = df_test_asset[x_cols].fillna(0)\n    y_test_asset = df_test_asset[y_col].fillna(0).values.ravel()\n    \n    val_size = 100\n    X_tr, X_val = X_train_full.iloc[:-val_size], X_train_full.iloc[-val_size:]\n    y_tr, y_val = y_train_full[:-val_size], y_train_full[-val_size:]\n    \n    train_set = lgb.Dataset(X_tr, label=y_tr)\n    val_set = lgb.Dataset(X_val, label=y_val, reference=train_set)\n    \n    model = lgb.train(\n        params,\n        train_set,\n        num_boost_round=2000,\n        valid_sets=[val_set],\n        callbacks=[lgb.early_stopping(stopping_rounds=100)]\n    )\n    \n\n    y_pred_val = model.predict(X_val)\n    mse_val = mean_squared_error(y_val, y_pred_val)\n    try:\n        corr_val, _ = pearsonr(y_val, y_pred_val)\n    except:\n        corr_val = np.nan\n    print(f\"Asset {asset} | VAL MSE={mse_val:.6f} | Pearson={corr_val if not np.isnan(corr_val) else 'nan'} | best_iter={model.best_iteration}\")\n    \n    final_model = lgb.train(params, lgb.Dataset(X_train_full, y_train_full), num_boost_round=model.best_iteration)\n    y_pred_test = final_model.predict(X_test_asset)\n    mse_test = mean_squared_error(y_test_asset, y_pred_test)\n    try:\n        corr_test, _ = pearsonr(y_test_asset, y_pred_test)\n    except:\n        corr_test = np.nan\n    \n    print(f\"Asset {asset} | TEST MSE={mse_test:.6f} | Pearson={corr_test if not np.isnan(corr_test) else 'nan'}\")\n    \n    w = asset_weights[asset]\n    all_y_true.append(y_test_asset)\n    all_y_pred.append(y_pred_test)\n    all_weights.append(np.full_like(y_test_asset, w, dtype=float))\n    \n    #gain_importance = final_model.feature_importance(importance_type='gain')\n    #print(f\"Asset {asset} | Feature Importance (gain): {dict(zip(x_cols, gain_importance))}\")\n    #explainer = shap.TreeExplainer(final_model)\n    #shap_values = explainer.shap_values(X_test_asset)\n    #shap.summary_plot(shap_values, X_test_asset, show=False)\n\ny_true_all = np.concatenate(all_y_true)\ny_pred_all = np.concatenate(all_y_pred)\nw_all      = np.concatenate(all_weights)\n\nweighted_corr = weighted_pearsonr(y_true_all, y_pred_all, w_all)\nprint(f\"Aggregated Weighted Pearson: {weighted_corr:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T02:25:12.956372Z","iopub.execute_input":"2025-12-17T02:25:12.956701Z","iopub.status.idle":"2025-12-17T03:12:07.086735Z","shell.execute_reply.started":"2025-12-17T02:25:12.956679Z","shell.execute_reply":"2025-12-17T03:12:07.083910Z"}},"outputs":[{"name":"stderr","text":"Assets:   0%|          | 0/14 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[514]\tvalid_0's l2: 0.00334971\nAsset 0 | VAL MSE=0.003350 | Pearson=0.9988068665825638 | best_iter=514\n","output_type":"stream"},{"name":"stderr","text":"Assets:   7%|▋         | 1/14 [01:48<23:31, 108.55s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 0 | TEST MSE=0.000005 | Pearson=0.7921015730634521\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[637]\tvalid_0's l2: 0.00173723\nAsset 1 | VAL MSE=0.001737 | Pearson=0.9993570361260662 | best_iter=637\n","output_type":"stream"},{"name":"stderr","text":"Assets:  14%|█▍        | 2/14 [04:09<25:32, 127.73s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 1 | TEST MSE=0.000168 | Pearson=0.1881802748239657\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[962]\tvalid_0's l2: 1.80397e-05\nAsset 2 | VAL MSE=0.000018 | Pearson=0.9999204906743178 | best_iter=962\n","output_type":"stream"},{"name":"stderr","text":"Assets:  21%|██▏       | 3/14 [06:49<26:05, 142.29s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 2 | TEST MSE=0.000005 | Pearson=0.7755032185541944\nTraining until validation scores don't improve for 100 rounds\nDid not meet early stopping. Best iteration is:\n[1997]\tvalid_0's l2: 2.9077e-05\nAsset 3 | VAL MSE=0.000029 | Pearson=0.9999640716604302 | best_iter=1997\n","output_type":"stream"},{"name":"stderr","text":"Assets:  29%|██▊       | 4/14 [11:20<32:13, 193.34s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 3 | TEST MSE=0.000031 | Pearson=0.4921404988296343\nTraining until validation scores don't improve for 100 rounds\nDid not meet early stopping. Best iteration is:\n[1953]\tvalid_0's l2: 6.43263e-06\nAsset 4 | VAL MSE=0.000006 | Pearson=0.9999578550023354 | best_iter=1953\n","output_type":"stream"},{"name":"stderr","text":"Assets:  36%|███▌      | 5/14 [14:19<28:13, 188.16s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 4 | TEST MSE=0.000119 | Pearson=0.3969668370749251\nTraining until validation scores don't improve for 100 rounds\nDid not meet early stopping. Best iteration is:\n[1993]\tvalid_0's l2: 1.80123e-05\nAsset 5 | VAL MSE=0.000018 | Pearson=0.9999286419866127 | best_iter=1993\n","output_type":"stream"},{"name":"stderr","text":"Assets:  43%|████▎     | 6/14 [19:21<30:14, 226.83s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 5 | TEST MSE=0.000021 | Pearson=0.6786962811144006\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[879]\tvalid_0's l2: 0.000137714\nAsset 6 | VAL MSE=0.000138 | Pearson=0.9998999100945309 | best_iter=879\n","output_type":"stream"},{"name":"stderr","text":"Assets:  50%|█████     | 7/14 [22:15<24:25, 209.37s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 6 | TEST MSE=0.000019 | Pearson=0.44451967944315074\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1564]\tvalid_0's l2: 1.32227e-05\nAsset 7 | VAL MSE=0.000013 | Pearson=0.9999424270742608 | best_iter=1564\n","output_type":"stream"},{"name":"stderr","text":"Assets:  57%|█████▋    | 8/14 [26:29<22:21, 223.61s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 7 | TEST MSE=0.000004 | Pearson=0.8394570764216289\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1266]\tvalid_0's l2: 0.00071742\nAsset 8 | VAL MSE=0.000717 | Pearson=0.9997721694209172 | best_iter=1266\n","output_type":"stream"},{"name":"stderr","text":"Assets:  64%|██████▍   | 9/14 [29:40<17:47, 213.58s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 8 | TEST MSE=0.000130 | Pearson=0.7552705727747192\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1405]\tvalid_0's l2: 6.16034e-06\nAsset 9 | VAL MSE=0.000006 | Pearson=0.999973438149446 | best_iter=1405\n","output_type":"stream"},{"name":"stderr","text":"Assets:  71%|███████▏  | 10/14 [33:28<14:31, 217.84s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 9 | TEST MSE=0.000115 | Pearson=0.25507734415091576\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[771]\tvalid_0's l2: 0.472\nAsset 10 | VAL MSE=0.472000 | Pearson=0.9731250682323639 | best_iter=771\n","output_type":"stream"},{"name":"stderr","text":"Assets:  79%|███████▊  | 11/14 [35:25<09:20, 186.97s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 10 | TEST MSE=0.000304 | Pearson=0.3216529721879139\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[744]\tvalid_0's l2: 0.000864333\nAsset 11 | VAL MSE=0.000864 | Pearson=0.9996995179697388 | best_iter=744\n","output_type":"stream"},{"name":"stderr","text":"Assets:  86%|████████▌ | 12/14 [37:53<05:50, 175.13s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 11 | TEST MSE=0.000020 | Pearson=0.7301661337631803\nTraining until validation scores don't improve for 100 rounds\nDid not meet early stopping. Best iteration is:\n[2000]\tvalid_0's l2: 3.05031e-05\nAsset 12 | VAL MSE=0.000031 | Pearson=0.9999510151499497 | best_iter=2000\n","output_type":"stream"},{"name":"stderr","text":"Assets:  93%|█████████▎| 13/14 [42:24<03:24, 204.34s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 12 | TEST MSE=0.000109 | Pearson=0.3525124871919485\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[1817]\tvalid_0's l2: 0.00495233\nAsset 13 | VAL MSE=0.004952 | Pearson=0.9983820908090268 | best_iter=1817\n","output_type":"stream"},{"name":"stderr","text":"Assets: 100%|██████████| 14/14 [46:53<00:00, 201.00s/it]","output_type":"stream"},{"name":"stdout","text":"Asset 13 | TEST MSE=0.000028 | Pearson=0.47632604335085366\nAggregated Weighted Pearson: 0.410940\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":22}]}